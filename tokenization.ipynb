{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP+hC1NoDnFyw4FtZMYDFcy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ismoil27/jaydariGPT/blob/main/tokenization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tg_bTtqtz3a",
        "outputId": "82bb5678-428e-4464-8240-4d83da6bab74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello world!\n"
          ]
        }
      ],
      "source": [
        "print('Hello world!') # token\n",
        "# 1 word => 1 token\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'Hello world this is a simple example to show how tokenization works in NLP and a sentence' # 17 token\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGdzW7qmt3ZY",
        "outputId": "129982e2-88f1-4f5d-a3f9-e4b782a142be"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello world this is a simple example to show how tokenization works in NLP and a sentence\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = text.split()\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LylACEklulil",
        "outputId": "cb438f3c-5adc-4662-d275-6d6e882616b5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', 'world', 'this', 'is', 'a', 'simple', 'example', 'to', 'show', 'how', 'tokenization', 'works', 'in', 'NLP', 'and', 'a', 'sentence']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {}\n",
        "current_id = 0\n",
        "\n",
        "for token in tokens:\n",
        "  if token not in vocab:\n",
        "    vocab[token] = current_id\n",
        "    current_id +=1\n",
        "\n",
        "print(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfcphfUnu7ee",
        "outputId": "df15bd54-0ec9-4af2-e558-4ab580887902"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Hello': 0, 'world': 1, 'this': 2, 'is': 3, 'a': 4, 'simple': 5, 'example': 6, 'to': 7, 'show': 8, 'how': 9, 'tokenization': 10, 'works': 11, 'in': 12, 'NLP': 13, 'and': 14, 'sentence': 15}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded = [vocab[token] for token in tokens]\n",
        "print(encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hMNYzncwNdD",
        "outputId": "c33b2e5d-7869-4e26-c77e-b3de1cd62b86"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 4, 15]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reverse_vocab = {id: token for token, id in vocab.items()}\n",
        "decoded = \" \".join([reverse_vocab[id] for id in encoded])\n",
        "print(decoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oAZsjoywxRM",
        "outputId": "3fa9ed94-d736-4d73-fcaf-91ac80496cb1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello world this is a simple example to show how tokenization works in NLP and a sentence\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Embedding vector => dense numerical array | Vector Database\n",
        "# 0 => [0.41, 0.22, -0.77, 0.56.........]\n",
        "# 1 => [0.34, 0.72, 0.77, 0.82.........]"
      ],
      "metadata": {
        "id": "pa5_-fLrxL0e"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "embedding_dim = 8\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "embedding_layer = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "input_ids = torch.tensor([encoded])\n",
        "embeddings = embedding_layer(input_ids)\n",
        "\n",
        "\n",
        "print(embeddings)\n",
        "print(embeddings.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Qq10qX_yPdL",
        "outputId": "c014ec29-0ffe-4a16-cbd3-d24c9c8e4fa2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0.5276, -0.9908,  0.2874,  0.1141,  0.3718, -1.5595, -0.2012,\n",
            "           0.0529],\n",
            "         [-0.9146, -0.5181,  2.1544,  0.1130, -0.2820, -0.5711,  1.1341,\n",
            "           0.9625],\n",
            "         [ 0.2334,  1.3587, -1.0221,  0.7003, -1.2843, -0.4557,  0.7737,\n",
            "           0.2525],\n",
            "         [ 0.7175, -0.6016,  0.4141, -0.2312,  0.7543,  0.6387,  1.2241,\n",
            "           0.2134],\n",
            "         [-0.4261, -1.2415,  0.8351,  0.5312,  0.1253, -1.1182,  0.5061,\n",
            "           0.6036],\n",
            "         [ 1.0686, -0.7113, -0.1063, -1.1104,  0.0312, -0.2841,  0.4086,\n",
            "           0.0828],\n",
            "         [ 1.0563,  0.0329, -0.7363,  1.0550,  0.0340,  1.1652,  1.2748,\n",
            "           0.1705],\n",
            "         [-1.7670,  1.1487, -1.2559,  0.0370,  0.5767,  1.3668,  0.7611,\n",
            "          -0.1505],\n",
            "         [ 1.4143,  0.0706, -2.1860, -0.3760,  0.5271,  0.8137, -0.8613,\n",
            "          -1.0598],\n",
            "         [ 0.5756,  1.2482, -0.4890,  1.6304, -0.1118, -1.3652, -1.7047,\n",
            "           0.5986],\n",
            "         [-0.6273,  1.0091, -0.4202,  0.0336,  2.1547,  0.3286,  0.1593,\n",
            "          -2.3816],\n",
            "         [-0.8001, -0.2443, -2.3883, -1.2412, -0.9267,  0.5673, -0.6341,\n",
            "           1.6136],\n",
            "         [-0.8728, -0.0482, -0.7054, -0.1977, -0.6275, -0.5134, -0.8700,\n",
            "           0.3158],\n",
            "         [-0.7668, -0.6497, -0.6484,  1.5155, -1.1414, -0.4086,  1.9293,\n",
            "           1.6135],\n",
            "         [ 0.0283,  1.0058,  0.3714,  1.1284, -0.1518, -1.7928,  0.4524,\n",
            "           0.0724],\n",
            "         [-0.4261, -1.2415,  0.8351,  0.5312,  0.1253, -1.1182,  0.5061,\n",
            "           0.6036],\n",
            "         [ 1.2174,  1.0187, -1.4297,  0.1075,  0.1173, -0.7613, -1.0456,\n",
            "          -1.1136]]], grad_fn=<EmbeddingBackward0>)\n",
            "torch.Size([1, 17, 8])\n"
          ]
        }
      ]
    }
  ]
}